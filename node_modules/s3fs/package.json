{
  "_args": [
    [
      "git+https://github.com/RiptideElements/s3fs.git",
      "C:\\Users\\SaulF\\Documents\\GitHub\\SPIA"
    ]
  ],
  "_from": "git+https://github.com/RiptideElements/s3fs.git",
  "_id": "s3fs@2.5.0",
  "_inCache": true,
  "_installable": true,
  "_location": "/s3fs",
  "_phantomChildren": {
    "buffer": "4.9.1",
    "crypto-browserify": "1.0.9",
    "jmespath": "0.15.0",
    "querystring": "0.2.0",
    "sax": "1.1.5",
    "url": "0.10.3",
    "xml2js": "0.4.15",
    "xmlbuilder": "2.6.2"
  },
  "_requested": {
    "hosted": {
      "directUrl": "https://raw.githubusercontent.com/RiptideElements/s3fs/master/package.json",
      "gitUrl": "git://github.com/RiptideElements/s3fs.git",
      "httpsUrl": "git+https://github.com/RiptideElements/s3fs.git",
      "shortcut": "github:RiptideElements/s3fs",
      "ssh": "git@github.com:RiptideElements/s3fs.git",
      "sshUrl": "git+ssh://git@github.com/RiptideElements/s3fs.git",
      "type": "github"
    },
    "name": null,
    "raw": "git+https://github.com/RiptideElements/s3fs.git",
    "rawSpec": "git+https://github.com/RiptideElements/s3fs.git",
    "scope": null,
    "spec": "git+https://github.com/RiptideElements/s3fs.git",
    "type": "hosted"
  },
  "_requiredBy": [
    "#USER"
  ],
  "_resolved": "git+https://github.com/RiptideElements/s3fs.git#26fb419f1ad5847507e4a6a6f637051bb11a9ff8",
  "_shasum": "cad99e1264597636df84e56a347371a8c21c8417",
  "_shrinkwrap": {
    "dependencies": {
      "aws-sdk": {
        "from": "aws-sdk@>=2.5.2 <2.6.0",
        "resolved": "https://registry.npmjs.org/aws-sdk/-/aws-sdk-2.5.2.tgz",
        "version": "2.5.2"
      },
      "bluebird": {
        "from": "bluebird@>=3.4.1 <3.5.0",
        "resolved": "https://registry.npmjs.org/bluebird/-/bluebird-3.4.1.tgz",
        "version": "3.4.1"
      },
      "extend": {
        "from": "extend@>=3.0.0 <4.0.0",
        "resolved": "https://registry.npmjs.org/extend/-/extend-3.0.0.tgz",
        "version": "3.0.0"
      },
      "jmespath": {
        "from": "jmespath@0.15.0",
        "resolved": "https://registry.npmjs.org/jmespath/-/jmespath-0.15.0.tgz",
        "version": "0.15.0"
      },
      "lodash": {
        "from": "lodash@>=3.5.0 <3.6.0",
        "resolved": "https://registry.npmjs.org/lodash/-/lodash-3.5.0.tgz",
        "version": "3.5.0"
      },
      "sax": {
        "from": "sax@1.1.5",
        "resolved": "https://registry.npmjs.org/sax/-/sax-1.1.5.tgz",
        "version": "1.1.5"
      },
      "xml2js": {
        "from": "xml2js@0.4.15",
        "resolved": "https://registry.npmjs.org/xml2js/-/xml2js-0.4.15.tgz",
        "version": "0.4.15"
      },
      "xmlbuilder": {
        "from": "xmlbuilder@2.6.2",
        "resolved": "https://registry.npmjs.org/xmlbuilder/-/xmlbuilder-2.6.2.tgz",
        "version": "2.6.2"
      }
    },
    "name": "s3fs",
    "version": "2.5.0"
  },
  "_spec": "git+https://github.com/RiptideElements/s3fs.git",
  "_where": "C:\\Users\\SaulF\\Documents\\GitHub\\SPIA",
  "author": {
    "email": "davidtpate@gmail.com",
    "name": "David Pate",
    "url": "https://github.com/DavidTPate"
  },
  "bugs": {
    "url": "http://github.com/RiptideElements/s3fs/issues"
  },
  "contributors": [
    {
      "email": "Jhorlin@gmail.com",
      "name": "Jhorlin De Armas",
      "url": "https://github.com/Jhorlin"
    }
  ],
  "dependencies": {
    "aws-sdk": "~2.6.9",
    "bluebird": "~3.4.6",
    "extend": "~3.x"
  },
  "description": "Implementation of Node.JS FS interface using Amazon Simple Storage Service (S3).",
  "devDependencies": {
    "buddy.js": "~0.x",
    "chai": "~3.x",
    "chai-as-promised": "~6.0.0",
    "dirty-chai": "~1.2.2",
    "eslint": "~3.7.1",
    "istanbul": "~0.4.5",
    "jscs": "~3.0.7",
    "jsinspect": "~0.x",
    "mocha": "~3.1.2",
    "nsp": "~2.6.2",
    "through2": "~2.x"
  },
  "gitHead": "26fb419f1ad5847507e4a6a6f637051bb11a9ff8",
  "homepage": "http://github.com/RiptideElements/s3fs",
  "keywords": [
    "s3fs",
    "amazon s3",
    "aws s3",
    "fs",
    "file system",
    "simple storage service",
    "amazon"
  ],
  "license": "MIT",
  "main": "index.js",
  "name": "s3fs",
  "optionalDependencies": {},
  "readme": "# S3FS\r\n[![npm](https://img.shields.io/npm/v/s3fs.svg)](https://www.npmjs.com/package/s3fs)\r\n[![npm](https://img.shields.io/npm/dm/s3fs.svg)](https://www.npmjs.com/package/s3fs)\r\n[![Build Status](https://travis-ci.org/RiptideElements/s3fs.svg?branch=master)](https://travis-ci.org/RiptideElements/s3fs)\r\n[![Coverage Status](https://img.shields.io/coveralls/RiptideElements/s3fs.svg)](https://coveralls.io/r/RiptideElements/s3fs)\r\n[![Codacy](https://img.shields.io/codacy/13e0385fd6fc4929a2d1a974c7d0d67f.svg)](https://www.codacy.com/public/davidtpate/s3fs)\r\n[![Code Climate](https://codeclimate.com/github/RiptideElements/s3fs/badges/gpa.svg)](https://codeclimate.com/github/RiptideElements/s3fs)\r\n[![David](https://img.shields.io/david/RiptideElements/s3fs.svg)](https://david-dm.org/RiptideElements/s3fs)\r\n[![David](https://img.shields.io/david/dev/RiptideElements/s3fs.svg)](https://david-dm.org/RiptideElements/s3fs)\r\n[![David](https://img.shields.io/david/peer/RiptideElements/s3fs.svg)](https://david-dm.org/RiptideElements/s3fs)\r\n\r\nImplementation of Node.JS [FS interface](http://nodejs.org/api/fs.html) using [Amazon Simple Storage Service (S3)](http://aws.amazon.com/s3/) for storage.\r\n\r\n**Lead Maintainer**: [David Pate](https://github.com/DavidTPate)\r\n\r\n## Purpose\r\nS3FS provides a drop-in replacement for the File System (FS) implementation that is available with Node.JS allowing a distributed file-system to be used\r\nby Node.JS applications through the well-known [FS interface](http://nodejs.org/api/fs.html) used by Node.JS.\r\n\r\n## Minimum IAM Policy\r\nBelow is a policy for AWS [Identity and Access Management](http://aws.amazon.com/iam/) which provides the minimum privileges needed to use S3FS.\r\n\r\n```json\r\n{\r\n  \"Statement\": [\r\n    {\r\n      \"Action\": [\r\n        \"s3:ListBucket\"\r\n      ],\r\n      \"Effect\": \"Allow\",\r\n      \"Resource\": [\r\n        \"arn:aws:s3:::your-bucket\"\r\n      ]\r\n    },\r\n    {\r\n      \"Action\": [\r\n        \"s3:AbortMultipartUpload\",\r\n        \"s3:CreateBucket\",\r\n        \"s3:DeleteBucket\",\r\n        \"s3:DeleteBucketPolicy\",\r\n        \"s3:DeleteObject\",\r\n        \"s3:GetBucketPolicy\",\r\n        \"s3:GetLifecycleConfiguration\",\r\n        \"s3:GetObject\",\r\n        \"s3:ListBucket\",\r\n        \"s3:ListBucketMultipartUploads\",\r\n        \"s3:ListMultipartUploadParts\",\r\n        \"s3:PutBucketPolicy\",\r\n        \"s3:PutLifecycleConfiguration\",\r\n        \"s3:PutObject\"\r\n      ],\r\n      \"Effect\": \"Allow\",\r\n      \"Resource\": [\r\n        \"arn:aws:s3:::your-bucket/*\"\r\n      ]\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n## Currently Supported Methods\r\nThe methods below from Node.JS's [FS interface](http://nodejs.org/api/fs.html) are the only currently supported methods\r\nmatching the signature and functionality of the `fs` module. All of the methods support either usage through callbacks\r\nor promises. There isn't any support for synchronous actions currently as there isn't a need.\r\n\r\n* [fs.createReadStream(path, [options])](http://nodejs.org/api/fs.html#fs_fs_createreadstream_path_options)\r\n* [fs.createWriteStream(path, [options])](http://nodejs.org/api/fs.html#fs_fs_createwritestream_path_options)\r\n* [fs.exists(path, callback)](http://nodejs.org/api/fs.html#fs_fs_exists_path_callback)\r\n* [fs.stat(path, callback)](http://nodejs.org/api/fs.html#fs_fs_stat_path_callback)\r\n* [fs.lstat(path, callback)](http://nodejs.org/api/fs.html#fs_fs_lstat_path_callback)\r\n* [fs.mkdir(path, [mode], callback)](http://nodejs.org/api/fs.html#fs_fs_mkdir_path_mode_callback)\r\n* [fs.readdir(path, callback)](http://nodejs.org/api/fs.html#fs_fs_readdir_path_callback)\r\n* [fs.readFile(filename, [options], callback)](http://nodejs.org/api/fs.html#fs_fs_readfile_filename_options_callback)\r\n* [fs.rmdir(path, callback)](http://nodejs.org/api/fs.html#fs_fs_rmdir_path_callback)\r\n* [fs.unlink(path, callback)](http://nodejs.org/api/fs.html#fs_fs_unlink_path_callback)\r\n* [fs.writeFile(filename, data, [options], callback)](http://nodejs.org/api/fs.html#fs_fs_writefile_filename_data_options_callback)\r\n\r\n### Constructor Details\r\nCreating an instance of `S3fs` takes in the `bucketPath` and `options` which are passed on to the [S3 constructor](http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#constructor-property).\r\n\r\n```js\r\nvar bucketPath = 'mySuperCoolBucket';\r\nvar s3Options = {\r\n  region: 'us-east-1',\r\n  \r\n};\r\nvar fsImpl = new S3FS(bucketPath, s3Options);\r\n```\r\n\r\n### Example Callback Usage\r\n```js\r\nvar S3FS = require('s3fs');\r\nvar fsImpl = new S3FS('test-bucket', options);\r\nfsImpl.writeFile('message.txt', 'Hello Node', function (err) {\r\n  if (err) throw err;\r\n  console.log('It\\'s saved!');\r\n});\r\n```\r\n\r\n### Example Promise Usage\r\n```js\r\nvar S3FS = require('s3fs');\r\nvar fsImpl = new S3FS('test-bucket', options);\r\nfsImpl.writeFile('message.txt', 'Hello Node').then(function() {\r\n  console.log('It\\'s saved!');\r\n}, function(reason) {\r\n  throw reason;\r\n});\r\n```\r\n\r\n## Custom Supported Methods\r\nBesides the methods from Node.JS's [FS interface](http://nodejs.org/api/fs.html) we also support some custom expansions\r\nto the interface providing various methods such as recursive methods and S3 specific methods. They are described below.\r\n\r\n### s3fs.getPath(path)\r\nProvides a location by concatenating the bucket with path(s).\r\n\r\n* path `String`. _Optional_. The relative path to the working directory or file\r\n\r\n```js\r\n // Create an instance of S3FS which has a current working directory of `test-folder` within the S3 bucket `test-bucket`\r\n var fsImpl = new S3FS('test-bucket/test-folder', options);\r\n \r\n // Returns location to directory `test-bucket/test-folder/styles\r\n var fsImplStyles = fsImpl.getPath('styles');\r\n // Returns location to file `test-bucket/test-folder/styles/main.css\r\n var fsImplStyles = fsImpl.getPath('styles/main.css');\r\n // Returns location to file `test-bucket/test-folder\r\n var fsImplStyles = fsImpl.getPath();\r\n```\r\n\r\n### s3fs.clone(path)\r\nProvides a clone of the instance of S3FS which has relative access to the specified directory.\r\n\r\n* path `String`. _Optional_. The relative path to extend the current working directory\r\n\r\n```js\r\n// Create an instance of S3FS which has a current working directory of `test-folder` within the S3 bucket `test-bucket`\r\nvar fsImpl = new S3FS('test-bucket/test-folder', options);\r\n// Creates a copy (which uses the same instance of S3FS) which has a current working directory of `test-folder/styles`\r\nvar fsImplStyles = fsImpl.clone('styles');\r\n```\r\n\r\n### s3fs.copyFile(sourcePath, destinationPath[, options, callback])\r\nAllows a file to be copied from one path to another path within the same bucket. Paths are relative to\r\nthe bucket originally provided.\r\n\r\n* sourceFile `String`. **Required**. Relative path to the source file\r\n* destinationFile `String`. **Required**. Relative path to the destination file\r\n* options `Object`. _Optional_. The options to be used when copying the file. See [AWS SDK](http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#copyObject-property)\r\n* callback `Function`. _Optional_. Callback to be used, if not provided will return a Promise\r\n\r\n```js\r\nvar fsImpl = new S3FS('test-bucket', options);\r\nfsImpl.copyFile('test-folder/test-file.txt', 'other-folder/test-file.txt').then(function(data) {\r\n  // File was successfully copied\r\n  // Data contains details such as the `ETag` about the object. See [AWS SDK](http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#copyObject-property) for details.\r\n}, function(reason) {\r\n  // Something went wrong\r\n});\r\n```\r\n\r\n### s3fs.copyDir(sourcePath, destinationPath[, callback])\r\nRecursively copies a directory from the source path to the destination path.\r\n\r\n* sourcePath `String`. **Required**. The source directory to be copied\r\n* destinationPath `String`. **Required**. The destination directory to be copied to\r\n* callback `Function`. _Optional_. Callback to be used, if not provided will return a Promise\r\n\r\n```js\r\nvar fsImpl = new S3FS('test-bucket', options);\r\nfsImpl.copyDir('test-folder', 'other-folder').then(function() {\r\n  // Directory was successfully copied\r\n}, function(reason) {\r\n  // Something went wrong\r\n});\r\n```\r\n\r\n### s3fs.create(options[, callback])\r\nCreates a new bucket on S3.\r\n\r\n* options `Object`. _Optional_. The options to be used when creating the bucket. See [AWS SDK](http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#createBucket-property)\r\n* callback `Function`. _Optional_. Callback to be used, if not provided will return a Promise\r\n\r\n```js\r\nvar fsImpl = new S3FS('test-bucket', options);\r\nfsImpl.create().then(function() {\r\n  // Bucket was successfully created\r\n}, function(reason) {\r\n  // Something went wrong\r\n});\r\n```\r\n\r\n### s3fs.delete([callback])\r\nDeletes a bucket on S3, can only be deleted when empty. If you need to delete one that isn't empty use\r\n[`destroy([callback])`](#s3fsdestroycallback) instead.\r\n\r\n* callback `Function`. _Optional_. Callback to be used, if not provided will return a Promise\r\n\r\n```js\r\nvar fsImpl = new S3FS('test-bucket', options);\r\nfsImpl.delete().then(function() {\r\n  // Bucket was successfully deleted\r\n}, function(reason) {\r\n  // Something went wrong\r\n});\r\n```\r\n\r\n### s3fs.destroy([callback])\r\nRecursively deletes all files within the bucket and then deletes the bucket.\r\n\r\n* callback `Function`. _Optional_. Callback to be used, if not provided will return a Promise\r\n\r\n```js\r\nvar fsImpl = new S3FS('test-bucket', options);\r\nfsImpl.destroy().then(function() {\r\n  // Bucket was successfully destroyed\r\n}, function(reason) {\r\n  // Something went wrong\r\n});\r\n```\r\n\r\n### s3fs.headObject(path[, callback])\r\nRetrieves the details about an object, but not the contents.\r\n\r\n* path `String`. **Required**. Path to the object to retrieve the head for\r\n* callback `Function`. _Optional_. Callback to be used, if not provided will return a Promise\r\n\r\n```js\r\nvar fsImpl = new S3FS('test-bucket', options);\r\nfsImpl.headObject('test-file.txt').then(function(details) {\r\n  // Details contains details such as the `ETag` about the object. See [AWS SDK](http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#headObject-property) for details.\r\n}, function(reason) {\r\n  // Something went wrong\r\n});\r\n```\r\n\r\n### s3fs.listContents(path, marker[, callback])\r\nRetrieves a list of all objects within the specific path. The result is similar to that of [`headObject(path[, callback])`](#s3fsheadobjectpath-callback)\r\nexpect that it contains an array of objects.\r\n\r\n* path `String`. **Required**. The path to list all of the objects for\r\n* marker `String`. **Required**. The key to start with when listing objects\r\n* callback `Function`. _Optional_. Callback to be used, if not provided will return a Promise\r\n\r\n```js\r\nvar fsImpl = new S3FS('test-bucket', options);\r\nfsImpl.listContents('/', '/').then(function(data) {\r\n  // Data.Contents contains details such as the `ETag` about the object. See [AWS SDK](http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#headObject-property) for details.\r\n}, function(reason) {\r\n  // Something went wrong\r\n});\r\n```\r\n\r\n### s3fs.putBucketLifecycle(name, prefix, days[, callback])\r\nAdds/Updates a lifecycle on a bucket.\r\n\r\n* name `String`. **Required**. The name of the lifecycle. The value cannot be longer than 255 characters.\r\n* prefix `String`. **Required**. Prefix identifying one or more objects to which the rule applies.\r\n* days Indicates the lifetime, in days, of the objects that are subject to the rule. The value must be a non-zero positive integer.\r\n* callback `Function`. _Optional_. Callback to be used, if not provided will return a Promise\r\n\r\n```js\r\nvar fsImpl = new S3FS('test-bucket', options);\r\n// Remove the Cached contents in the `/cache` directory each day.\r\nfsImpl.putBucketLifecycle('expire cache', 'cache', 1).then(function() {\r\n  // Bucket Lifecycle was successfully added/updated\r\n}, function(reason) {\r\n  // Something went wrong\r\n});\r\n```\r\n\r\n### s3fs.readdirp(path[, callback])\r\nRecursively reads a directory.\r\n\r\n* path `String`. **Required**. The path to the directory to read from\r\n\r\n```js\r\nvar fsImpl = new S3FS('test-bucket', options);\r\nfsImpl.readdirp('test-folder').then(function(files) {\r\n  // Files contains a list of all of the files similar to [`fs.readdir(path, callback)`](http://nodejs.org/api/fs.html#fs_fs_readdir_path_callback) but with recursive contents\r\n}, function(reason) {\r\n  // Something went wrong\r\n});\r\n```\r\n\r\n### s3fs.mkdirp(path[, callback])\r\nRecursively creates a directory.\r\n\r\n* path The path to the directory to create\r\n* callback `Function`. _Optional_. Callback to be used, if not provided will return a Promise\r\n\r\n```js\r\nvar fsImpl = new S3FS('test-bucket', options);\r\nfsImpl.mkdirp('test-folder').then(function() {\r\n  // Directory has been recursively created\r\n}, function(reason) {\r\n  // Something went wrong\r\n});\r\n```\r\n\r\n### s3fs.rmdirp(path[, callback])\r\nRecursively deletes a directory.\r\n\r\n* path The path to the directory to delete\r\n* callback `Function`. _Optional_. Callback to be used, if not provided will return a Promise\r\n\r\n```js\r\nvar fsImpl = new S3FS('test-bucket', options);\r\nfsImpl.rmdirp('test-folder').then(function() {\r\n  // Directory has been recursively deleted\r\n}, function(reason) {\r\n  // Something went wrong\r\n});\r\n```\r\n\r\n## Testing\r\nThis repository uses [Mocha](http://mochajs.org/) as its test runner. Tests can be run by executing the following command:\r\n\r\n```bash\r\nnpm test\r\n```\r\n\r\nThis will run all tests and report on their success/failure in the console, additionally it will include our [Code Coverage](#code-coverage).\r\n\r\n## Code Coverage\r\nThis repository uses [Istanbul](http://gotwarlost.github.io/istanbul/) as its code coverage tool. Code Coverage will be calculated when executing the following command:\r\n\r\n```bash\r\nnpm test\r\n```\r\n\r\nThis will report the Code Coverage to the console similar to the following:\r\n\r\n```bash\r\n=============================== Coverage summary ===============================\r\nStatements   : 78.07% ( 356/456 )\r\nBranches     : 50.23% ( 107/213 )\r\nFunctions    : 74.77% ( 83/111 )\r\nLines        : 78.07% ( 356/456 )\r\n================================================================================\r\n```\r\n\r\nAdditionally, an interactive HTML report will be generated in `./coverage/lcov-report/index.html` which allows browsing the coverage by file.\r\n\r\n\r\n## License\r\n[MIT](LICENSE)\r\n\r\n## Copyright\r\n> Copyright (c) 2015 Riptide Software Inc.\r\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git://github.com/RiptideElements/s3fs.git"
  },
  "scripts": {
    "cover": "istanbul cover _mocha -- --check-leaks --recursive --timeout=25000 test && istanbul check-coverage --statements 80.95 --branches 76.56 --functions 74.3 --lines 80.95",
    "lint": "eslint . && jscs . && jsinspect . && buddy --detect-objects index.js ./lib",
    "security": "nsp check",
    "test": "mocha --check-leaks --recursive --timeout=25000 test",
    "test-ci": "npm run lint && npm run security && npm run cover"
  },
  "version": "2.5.0"
}
